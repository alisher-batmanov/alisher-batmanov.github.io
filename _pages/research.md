---
layout: archive
title: "Research"
nav_order: 1
permalink: /research/
author_profile: true
---

{% include base_path %}


## Work in Progress

- <span style="color:#001f3d"><strong>“Mental Models, Social Learning and Statistical Discrimination: A Laboratory Study”</strong></span>
  <details>
    <summary style="cursor: pointer;">
      <strong>See others’ optimal choices: / learn by imitating, but / not when environment changes.</strong>
    </summary>
    <div style="margin-top: 0.4em;">
      <strong>Abstract:</strong> In economic decision-making, individuals often rely on subjective representation of the environment to process information and make inferences. Using a laboratory experiment, we investigate how such mental models transform when people are exposed to the evaluations of others, particularly in scenarios where one or more parties may adopt an incorrect or misspecified model. Participants face a hiring task where their goal is to choose a worker with higher ability by integrating a noisy education signal with prior group information. The design of treatment conditions variably exposes subjects to choices by another participant, using one group to present evaluations closely aligned with the theoretical Bayesian benchmark and another to expose subjects to evaluations from a participant exhibiting conservatism bias (signal neglect). We find that exposure to conservative choices leads to higher incidence of suboptimal behavior relative to exposure to Bayesian choices. Using elicited confidence measures and a diagnostic treatment with detailed feedback, we explore potential mechanisms. The results suggest that not recognizing the optimality of others’ choices partially hinders social learning. In addition, lower confidence in one’s choices is strongly associated with following others’ suboptimal actions, but not with learning from the optimal ones.
    </div>
  </details>

- <span style="color:#001f3d"><strong>“Stigma, Beliefs and Demand for Mental Health Services Among University Students”</strong></span>  
  (with Ida Grigoryeva, Bruno Calderon, Roberto González and Alejandro Guardiola Ramires)
  <details>
    <summary style="cursor: pointer;">
      <strong>Students don’t go to therapy, why? / Unlikely inaccurate beliefs: / info treatment decreases demand.</strong>
    </summary>
    <div style="margin-top: 0.4em;">
      <strong>Abstract:</strong> Despite high rates of mental health challenges such as depression and anxiety and the availability of effective treatment options, most university students do not seek professional help. This project examines the factors that shape the demand for mental health services among students, as well as the barriers that prevent them from seeking support. We conduct a representative survey at a large university in Mexico to establish baseline information on student mental health. Preliminary results indicate that nearly one-third of students report moderate or severe symptoms of depression and anxiety, yet most do not seek or receive adequate support, with only 40% of students in distress accessing professional help. Additionally, while students tend to believe that poor mental health correlates with lower grades, our data shows no evidence to support this. Our findings aim to inform interventions to reduce the mental health treatment gap in the university student population.
    </div>
  </details>

## Working Papers

- <strong>"Mass Reproducibility and Replicability: A New Hope" (2024)</strong>  
  (with Abel Brodeur, Derek Mikola, Nikolai Cook, et al.)
  <details>
    <summary style="cursor: pointer;">
      <strong>Replicate results of 110 papers: / computational reproducibility 85% and / robustness reproducibility 70% from 5,511 re-analyses.</strong>
    </summary>
    <div style="margin-top: 0.4em;">
      <strong>Abstract:</strong> This study pushes our understanding of research reliability by reproducing and replicating claims from 110 papers in leading economic and political science journals. The analysis involves computational reproducibility checks and robustness assessments. It reveals several patterns. First, we uncover a high rate of fully computationally reproducible results (over 85%). Second, excluding minor issues like missing packages or broken pathways, we uncover coding errors for about 25% of studies, with some studies containing multiple errors. Third, we test the robustness of the results to 5,511 re-analyses. We find a robustness reproducibility of about 70%. Robustness reproducibility rates are relatively higher for re-analyses that introduce new data and lower for re-analyses that change the sample or the definition of the dependent variable. Fourth, 52% of re-analysis effect size estimates are smaller than the original published estimates and the average statistical significance of a re-analysis is 77% of the original. Lastly, we rely on six teams of researchers working independently to answer eight additional research questions on the determinants of robustness reproducibility. Most teams find a negative relationship between replicators' experience and reproducibility, while finding no relationship between reproducibility and the provision of intermediate or even raw data combined with the necessary cleaning codes.
    </div>
  </details>

<!-- 
## Work in Progress

- <span style="color:#001f3d"><strong>“Mental Models, Social Learning and Statistical Discrimination: A Laboratory Study”</strong></span>
  <details>
    <summary style="cursor: pointer;">
      <small style="font-weight: bold;">See others’ optimal choices: / learn by imitating, but / not when environment changes.</small>
    </summary>
    <small style="display: block; margin-top: 0.4em;">
    <strong>Abstract:</strong> In economic decision-making, individuals often rely on subjective representation of the environment to process information and make inferences. Using a laboratory experiment, we investigate how such mental models transform when people are exposed to the evaluations of others, particularly in scenarios where one or more parties may adopt an incorrect or misspecified model. Participants face a hiring task where their goal is to choose a worker with higher ability by integrating a noisy education signal with prior group information. The design of treatment conditions variably exposes subjects to choices by another participant, using one group to present evaluations closely aligned with the theoretical Bayesian benchmark and another to expose subjects to evaluations from a participant exhibiting conservatism bias (signal neglect). We find that exposure to conservative choices leads to higher incidence of suboptimal behavior relative to exposure to Bayesian choices. Using elicited confidence measures and a diagnostic treatment with detailed feedback, we explore potential mechanisms. The results suggest that not recognizing the optimality of others’ choices partially hinders social learning. In addition, lower confidence in one’s choices is strongly associated with following others’ suboptimal actions, but not with learning from the optimal ones.
    </small>
  </details>

- <span style="color:#001f3d"><strong>“Stigma, Beliefs and Demand for Mental Health Services Among University Students”</strong></span>  
  <small>(with Ida Grigoryeva, Bruno Calderon, Roberto González and Alejandro Guardiola Ramires)</small>
  <details>
    <summary style="cursor: pointer;">
      <small style="font-weight: bold;">Students don’t go to therapy, why? / Unlikely inaccurate beliefs: / info treatment decreases demand.</small>
    </summary>
    <small style="display: block; margin-top: 0.4em;">
       <strong>Abstract:</strong> Despite high rates of mental health challenges such as depression and anxiety and the availability of effective treatment options, most university students do not seek professional help. This project examines the factors that shape the demand for mental health services among students, as well as the barriers that prevent them from seeking support. We conduct a representative survey at a large university in Mexico to establish baseline information on student mental health. Preliminary results indicate that nearly one-third of students report moderate or severe symptoms of depression and anxiety, yet most do not seek or receive adequate support, with only 40% of students in distress accessing professional help. Additionally, while students tend to believe that poor mental health correlates with lower grades, our data shows no evidence to support this. Our findings aim to inform interventions to reduce the mental health treatment gap in the university student population.
    </small>
  </details>

## Working Papers

- <strong>"Mass Reproducibility and Replicability: A New Hope" (2024)</strong>  
  <small>(with Abel Brodeur, Derek Mikola, Nikolai Cook, et al.)</small>
  <details>
    <summary style="cursor: pointer;">
      <small style="font-weight: bold;">Replicate results of 110 papers: / computational reproducibility 85% and / robustness reproducibility 70% from 5,511 re-analyses.</small>
    </summary>
    <small style="display: block; margin-top: 0.4em;">
       <strong>Abstract:</strong> This study pushes our understanding of research reliability by reproducing and replicating claims from 110 papers in leading economic and political science journals. The analysis involves computational reproducibility checks and robustness assessments. It reveals several patterns. First, we uncover a high rate of fully computationally reproducible results (over 85%). Second, excluding minor issues like missing packages or broken pathways, we uncover coding errors for about 25% of studies, with some studies containing multiple errors. Third, we test the robustness of the results to 5,511 re-analyses. We find a robustness reproducibility of about 70%. Robustness reproducibility rates are relatively higher for re-analyses that introduce new data and lower for re-analyses that change the sample or the definition of the dependent variable. Fourth, 52% of re-analysis effect size estimates are smaller than the original published estimates and the average statistical significance of a re-analysis is 77% of the original. Lastly, we rely on six teams of researchers working independently to answer eight additional research questions on the determinants of robustness reproducibility. Most teams find a negative relationship between replicators' experience and reproducibility, while finding no relationship between reproducibility and the provision of intermediate or even raw data combined with the necessary cleaning codes.
    </small>
  </details>
 -->




